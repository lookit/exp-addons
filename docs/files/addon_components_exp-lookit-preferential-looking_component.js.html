<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>addon/components/exp-lookit-preferential-looking/component.js - exp-player</title>
    <link rel="stylesheet" href="http://yui.yahooapis.com/3.9.1/build/cssgrids/cssgrids-min.css">
    <link rel="stylesheet" href="../assets/vendor/prettify/prettify-min.css">
    <link rel="stylesheet" href="../assets/css/main.css" id="site_styles">
    <link rel="icon" href="../assets/favicon.ico">
    <script src="http://yui.yahooapis.com/combo?3.9.1/build/yui/yui-min.js"></script>
</head>
<body class="yui3-skin-sam">

<div id="doc">
    <div id="hd" class="yui3-g header">
        <div class="yui3-u-3-4">
                <h1><img src="../assets/css/logo.png" title="exp-player" width="117" height="52"></h1>
        </div>
        <div class="yui3-u-1-4 version">
            <em>API Docs for: 0.5.1</em>
        </div>
    </div>
    <div id="bd" class="yui3-g">

        <div class="yui3-u-1-4">
            <div id="docs-sidebar" class="sidebar apidocs">
                <div id="api-list">
                    <h2 class="off-left">APIs</h2>
                    <div id="api-tabview" class="tabview">
                        <ul class="tabs">
                            <li><a href="#api-classes">Classes</a></li>
                            <li><a href="#api-modules">Modules</a></li>
                        </ul>
                
                        <div id="api-tabview-filter">
                            <input type="search" id="api-filter" placeholder="Type to filter APIs">
                        </div>
                
                        <div id="api-tabview-panel">
                            <ul id="api-classes" class="apis classes">
                                <li><a href="../classes/ExpExitSurvey.html">ExpExitSurvey</a></li>
                                <li><a href="../classes/ExpExitSurveyPilot.html">ExpExitSurveyPilot</a></li>
                                <li><a href="../classes/ExpFrameBase.html">ExpFrameBase</a></li>
                                <li><a href="../classes/ExpFrameBaseUnsafe.html">ExpFrameBaseUnsafe</a></li>
                                <li><a href="../classes/ExpLookitDialoguePage.html">ExpLookitDialoguePage</a></li>
                                <li><a href="../classes/ExpLookitExitSurvey.html">ExpLookitExitSurvey</a></li>
                                <li><a href="../classes/ExpLookitGeometryAlternation.html">ExpLookitGeometryAlternation</a></li>
                                <li><a href="../classes/ExpLookitInstructions.html">ExpLookitInstructions</a></li>
                                <li><a href="../classes/ExpLookitMoodQuestionnaire.html">ExpLookitMoodQuestionnaire</a></li>
                                <li><a href="../classes/ExpLookitPreferentialLooking.html">ExpLookitPreferentialLooking</a></li>
                                <li><a href="../classes/ExpLookitPreviewExplanation.html">ExpLookitPreviewExplanation</a></li>
                                <li><a href="../classes/ExpLookitStoryPage.html">ExpLookitStoryPage</a></li>
                                <li><a href="../classes/ExpLookitText.html">ExpLookitText</a></li>
                                <li><a href="../classes/ExpMoodQuestionnaire.html">ExpMoodQuestionnaire</a></li>
                                <li><a href="../classes/ExpPhysicsIntro.html">ExpPhysicsIntro</a></li>
                                <li><a href="../classes/ExpPhysicsPreVideo.html">ExpPhysicsPreVideo</a></li>
                                <li><a href="../classes/ExpPhysicsPreviewExplanation.html">ExpPhysicsPreviewExplanation</a></li>
                                <li><a href="../classes/ExpPlayer.html">ExpPlayer</a></li>
                                <li><a href="../classes/ExpVideoConfig.html">ExpVideoConfig</a></li>
                                <li><a href="../classes/ExpVideoConfigQuality.html">ExpVideoConfigQuality</a></li>
                                <li><a href="../classes/ExpVideoConsent.html">ExpVideoConsent</a></li>
                                <li><a href="../classes/ExpVideoPhysics.html">ExpVideoPhysics</a></li>
                                <li><a href="../classes/ExpVideoPreview.html">ExpVideoPreview</a></li>
                                <li><a href="../classes/FullScreen.html">FullScreen</a></li>
                                <li><a href="../classes/geometry.html">geometry</a></li>
                                <li><a href="../classes/MediaReload.html">MediaReload</a></li>
                                <li><a href="../classes/randomParameterSet.html">randomParameterSet</a></li>
                                <li><a href="../classes/videoRecorder.html">videoRecorder</a></li>
                                <li><a href="../classes/VideoRecorderObject.html">VideoRecorderObject</a></li>
                                <li><a href="../classes/VideoRecordMixin.html">VideoRecordMixin</a></li>
                            </ul>
                
                
                            <ul id="api-modules" class="apis modules">
                                <li><a href="../modules/components.html">components</a></li>
                                <li><a href="../modules/exp-player.html">exp-player</a></li>
                                <li><a href="../modules/frames.html">frames</a></li>
                                <li><a href="../modules/mixins.html">mixins</a></li>
                                <li><a href="../modules/randomizers.html">randomizers</a></li>
                                <li><a href="../modules/services.html">services</a></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="yui3-u-3-4">
                <div id="api-options">
                    Show:
                    <label for="api-show-inherited">
                        <input type="checkbox" id="api-show-inherited" checked>
                        Inherited
                    </label>
            
                    <label for="api-show-protected">
                        <input type="checkbox" id="api-show-protected">
                        Protected
                    </label>
            
                    <label for="api-show-private">
                        <input type="checkbox" id="api-show-private">
                        Private
                    </label>
                    <label for="api-show-deprecated">
                        <input type="checkbox" id="api-show-deprecated">
                        Deprecated
                    </label>
            
                </div>
            
            <div class="apidocs">
                <div id="docs-main">
                    <div class="content">
<h1 class="file-heading">File: addon/components/exp-lookit-preferential-looking/component.js</h1>

<div class="file">
    <pre class="code prettyprint linenums">
import Ember from &#x27;ember&#x27;;
import layout from &#x27;./template&#x27;;
import ExpFrameBaseUnsafeComponent from &#x27;../../components/exp-frame-base-unsafe/component&#x27;;
import FullScreen from &#x27;../../mixins/full-screen&#x27;;
import VideoRecord from &#x27;../../mixins/video-record&#x27;;

let {
    $
} = Ember;

/**
 * @module exp-player
 * @submodule frames
 */

/**
 * Frame to implement a basic preferential looking trial, with static images
 * displayed in the center or at left and right of the screen. Trial proceeds
 * in segments:
 * - Intro: central attentiongrabber video (looping) &amp; intro audio [wait until
 *   recording is established to move on, and a minimum amount of time]
 * - Test: image(s) displayed, any test audio played [set amount of time] OR
 * Calibration: calibration video displayed at center, left, right, center, each
 * for calibrationLength s.
 * - Final audio: central attentiongrabber video (looping) &amp; final audio
 *   (optional section, intended for last trial in block)
 *
 * There are three basic uses of this frame expected:
 * - Familiarization trial with a single central image. Provide a value for
 * centerImage, but not rightImage or leftImage.
 * - Test trial with right and left images. Provide a value for rightImage and
 * leftImage, but not centerImage. (There is no explicit &quot;preferential looking
 * vs. familiarization&quot; switch: all of the images provided will be displayed.)
 * - Calibration trial. Set isCalibrationFrame to true, and provide
 * calibrationLength (length of each calibration segment in s),
 * calibrationVideoSources, and calibrationAudioSources.
 *
 * This frame extends ExpFrameBaseUnsafe because it is displayed fullscreen
 * and is expected to be repeated.

&#x60;&#x60;&#x60;json
 &quot;frames&quot;: {
    &quot;preferential-looking&quot;: {
        &quot;kind&quot;: &quot;exp-lookit-preferential-looking&quot;,
        &quot;id&quot;: &quot;pref-trial&quot;,
        &quot;isCalibrationFrame&quot;: false,
        &quot;allowPausingDuringTest&quot;: true,
        &quot;baseDir&quot;: &quot;https://s3.amazonaws.com/lookitcontents/labelsconcepts/&quot;,
        &quot;audioTypes&quot;: [&quot;mp3&quot;, &quot;ogg&quot;],
        &quot;videoTypes&quot;: [&quot;webm&quot;, &quot;mp4&quot;],
        &quot;rightImage&quot;: &quot;fam.jpg&quot;,
        &quot;leftImage&quot;: &quot;novel.jpg&quot;,
        &quot;centerImage&quot;: &quot;0001.jpg&quot;,
        &quot;pauseAudio&quot;: [
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/geometry/mp3/pause.mp3&quot;,
                &quot;type&quot;: &quot;audio/mp3&quot;
            },
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/geometry/ogg/pause.ogg&quot;,
                &quot;type&quot;: &quot;audio/ogg&quot;
            }
        ],
        &quot;trialLength&quot;: 10,
        &quot;fsAudio&quot;: [
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/geometry/mp3/fullscreen.mp3&quot;,
                &quot;type&quot;: &quot;audio/mp3&quot;
            },
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/geometry/ogg/fullscreen.ogg&quot;,
                &quot;type&quot;: &quot;audio/ogg&quot;
            }
        ],
        &quot;calibrationLength&quot;: 3,
        &quot;attnLength&quot;: 1,
        &quot;endAudioSources&quot;: [
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/geometry/mp3/all_done.mp3&quot;,
                &quot;type&quot;: &quot;audio/mp3&quot;
            },
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/geometry/ogg/all_done.ogg&quot;,
                &quot;type&quot;: &quot;audio/ogg&quot;
            }
        ],
        &quot;introAudioSources&quot;: [
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/geometry/mp3/chimes.mp3&quot;,
                &quot;type&quot;: &quot;audio/mp3&quot;
            },
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/geometry/ogg/chimes.ogg&quot;,
                &quot;type&quot;: &quot;audio/ogg&quot;
            }
        ],
        &quot;testAudioSources&quot;: [
            {
                &quot;stub&quot;: &quot;Familiarization_find_dax_amplified_repeated&quot;
            }
        ],
        &quot;unpauseAudio&quot;: [
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/geometry/mp3/return_after_pause.mp3&quot;,
                &quot;type&quot;: &quot;audio/mp3&quot;
            },
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/geometry/ogg/return_after_pause.ogg&quot;,
                &quot;type&quot;: &quot;audio/ogg&quot;
            }
        ],
        &quot;calibrationVideoSources&quot;: [
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/geometry/webm/attention.webm&quot;,
                &quot;type&quot;: &quot;video/webm&quot;
            },
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/geometry/mp4/attention.mp4&quot;,
                &quot;type&quot;: &quot;video/mp4&quot;
            }
        ],
        &quot;videoSources&quot;: [
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/exp-physics-final/stimuli/attention/webm/attentiongrabber.webm&quot;,
                &quot;type&quot;: &quot;video/webm&quot;
            },
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/exp-physics-final/stimuli/attention/mp4/attentiongrabber.mp4&quot;,
                &quot;type&quot;: &quot;video/mp4&quot;
            }
        ],
        &quot;calibrationAudioSources&quot;: [
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/geometry/mp3/chimes.mp3&quot;,
                &quot;type&quot;: &quot;audio/mp3&quot;
            },
            {
                &quot;src&quot;: &quot;https://s3.amazonaws.com/lookitcontents/geometry/ogg/chimes.ogg&quot;,
                &quot;type&quot;: &quot;audio/ogg&quot;
            }
        ]
    }
 }

 * &#x60;&#x60;&#x60;
 * @class ExpLookitPreferentialLooking
 * @extends ExpFrameBaseUnsafe
 * @uses FullScreen
 * @uses VideoRecord
 */

export default ExpFrameBaseUnsafeComponent.extend(FullScreen, VideoRecord,  {
    // In the Lookit use case, the frame BEFORE the one that goes fullscreen
    // must use &quot;unsafe&quot; saves (in order for the fullscreen event to register as
    // being user-initiated and not from a promise handler) #LEI-369.
    // exp-alternation frames are expected to be repeated, so they need to be
    // unsafe.
    type: &#x27;exp-lookit-preferential-looking&#x27;,
    layout: layout,
    displayFullscreen: true, // force fullscreen for all uses of this component
    fullScreenElementId: &#x27;experiment-player&#x27;,
    fsButtonID: &#x27;fsButton&#x27;,
    videoRecorder: Ember.inject.service(),
    recorder: null,
    hasCamAccess: Ember.computed.alias(&#x27;recorder.hasCamAccess&#x27;),
    videoUploadConnected: Ember.computed.alias(&#x27;recorder.connected&#x27;),

    // Track state of experiment
    completedAudio: false,
    completedAttn: false,
    currentSegment: &#x27;intro&#x27;, // &#x27;calibration&#x27;, &#x27;test&#x27;, &#x27;finalaudio&#x27; (mutually exclusive)
    previousSegment: &#x27;intro&#x27;, // used when pausing/unpausing - refers to segment that study was paused during

    readyToStartCalibration: Ember.computed(&#x27;hasCamAccess&#x27;, &#x27;videoUploadConnected&#x27;, &#x27;completedAudio&#x27;, &#x27;completedAttn&#x27;,
        function() {
            return (this.get(&#x27;hasCamAccess&#x27;) &amp;&amp; this.get(&#x27;videoUploadConnected&#x27;) &amp;&amp; this.get(&#x27;completedAttn&#x27;) &amp;&amp; (!this.get(&#x27;hasBeenPaused&#x27;) || this.get(&#x27;completedAudio&#x27;)));
        }),

    // helpers for use in template
    doingCalibration: Ember.computed(&#x27;currentSegment&#x27;, function() {
        return (this.get(&#x27;currentSegment&#x27;) === &#x27;calibration&#x27;);
    }),
    doingIntro: Ember.computed(&#x27;currentSegment&#x27;, function() {
        return (this.get(&#x27;currentSegment&#x27;) === &#x27;intro&#x27;);
    }),
    doingTest: Ember.computed(&#x27;currentSegment&#x27;, function() {
        return (this.get(&#x27;currentSegment&#x27;) === &#x27;test&#x27;);
    }),
    doingFinalAudio: Ember.computed(&#x27;currentSegment&#x27;, function() {
        return (this.get(&#x27;currentSegment&#x27;) === &#x27;finalaudio&#x27;);
    }),

    isPaused: false,
    hasBeenPaused: false,
    skipTest: false,

    // Timers for intro &amp; stimuli
    introTimer: null, // minimum length of intro segment
    stimTimer: null,  // display of static images
    calTimer: null,   // display of calibration video

    meta: {
        name: &#x27;ExpLookitPreferentialLooking&#x27;,
        description: &#x27;Frame to implement specific test trial structure for geometry alternation experiment. Includes announcement, calibration, and alternation (test) phases. During &quot;alternation,&quot; two streams of triangles are shown, in rectangles on the left and right of the screen: one one side both size and shape change, on the other only size changes. Frame is displayed fullscreen and video recording is conducted during calibration/test.&#x27;,
        parameters: {
            type: &#x27;object&#x27;,
            properties: {
                /**
                 * Whether to do calibration instead of a static image display.
                 * If this is true, then provide calibrationLength,
                 * calibrationAudioSources, and calibrationVideoSources as well.
                 *
                 * @property {Boolean} isCalibrationFrame
                 * @default false
                 */
                isCalibrationFrame: {
                    type: &#x27;boolean&#x27;,
                    default: false,
                    description: &#x27;Whether to do calibration instead of a static image display&#x27;
                },
                /**
                 * Base directory for where to find stimuli. Any image src
                 * values that are not full paths will be expanded by prefixing
                 * with &#x60;baseDir&#x60; + &#x60;img/&#x60;. Any audio/video src values that give
                 * a value for &#x27;stub&#x27; rather than &#x27;src&#x27; and &#x27;type&#x27; will be
                 * expanded out to
                 * &#x60;baseDir/avtype/[stub].avtype&#x60;, where the potential avtypes
                 * are given by audioTypes and videoTypes.
                 *
                 * Note that baseDir SHOULD include a trailing slash
                 * (e.g., &#x60;http://stimuli.org/myexperiment/&#x60;, not
                 * &#x60;http://stimuli.org/myexperiment&#x60;)
                 *
                 * @property {String} baseDir
                 * @default &#x27;&#x27;
                 */
                baseDir: {
                    type: &#x27;string&#x27;,
                    default: &#x27;&#x27;,
                    description: &#x27;Base directory for all stimuli&#x27;
                },
                /**
                 * List of audio types to expect for any audio specified just
                 * with a string rather than with a list of src/type pairs.
                 * If audioTypes is [&#x27;typeA&#x27;, &#x27;typeB&#x27;] and an audio source
                 * (e.g. introAudioSources) is given as [{&#x27;stub&#x27;: &#x27;intro&#x27;}],
                 * then introAudioSources will be expanded out to
                 *
&#x60;&#x60;&#x60;json
                 [
                        {
                            src: &#x27;baseDir&#x27; + &#x27;typeA/intro.typeA&#x27;,
                            type: &#x27;audio/typeA&#x27;
                        },
                        {
                            src: &#x27;baseDir&#x27; + &#x27;typeB/intro.typeB&#x27;,
                            type: &#x27;audio/typeB&#x27;
                        }
                ]
&#x60;&#x60;&#x60;
                 *
                 * @property {String[]} audioTypes
                 * @default [&#x27;mp3&#x27;, &#x27;ogg&#x27;]
                 */
                audioTypes: {
                    type: &#x27;array&#x27;,
                    default: [&#x27;mp3&#x27;, &#x27;ogg&#x27;],
                    description: &#x27;List of audio types to expect for any audio sources specified as strings rather than lists of src/type pairs&#x27;
                },
                /**
                 * List of video types to expect for any video specified just
                 * with a string rather than with a list of src/type pairs.
                 * If video is [&#x27;typeA&#x27;, &#x27;typeB&#x27;] and an video source
                 * is given as {[&#x27;stub&#x27;: &#x27;attn&#x27;]}, then
                 * the video source will be expanded out to
                 *
&#x60;&#x60;&#x60;json
                 [
                        {
                            src: &#x27;baseDir&#x27; + &#x27;typeA/attn.typeA&#x27;,
                            type: &#x27;video/typeA&#x27;
                        },
                        {
                            src: &#x27;baseDir&#x27; + &#x27;typeB/attn.typeB&#x27;,
                            type: &#x27;video/typeB&#x27;
                        }
                ]
&#x60;&#x60;&#x60;
                 *
                 * @property {String[]} videoTypes
                 * @default [&#x27;mp3&#x27;, &#x27;ogg&#x27;]
                 */
                videoTypes: {
                    type: &#x27;array&#x27;,
                    default: [&#x27;webm&#x27;, &#x27;mp4&#x27;],
                    description: &#x27;List of video types to expect for any video sources specified as strings rather than lists of src/type pairs&#x27;
                },
                /**
                 * Whether to allow user to pause the study during the test
                 * segment and restart from intro; otherwise, user can pause but
                 * this frame will end upon unpausing. Applies to pausing during
                 * both image display and calibration segments. Pausing is
                 * always allowed during the intro.
                 *
                 * @property {Boolean} allowPausingDuringTest
                 */
                allowPausingDuringTest: {
                    type: &#x27;boolean&#x27;,
                    description: &#x27;Whether to allow user to pause the study during the test segment and restart from intro; otherwise, user can pause but this frame will end upon unpausing&#x27;
                },
                /**
                 * URL of image to show on left, if any. Can be a full URL or a
                 * stub that will be appended to &#x60;baseDir&#x60; + &#x60;img/&#x60; (see
                 * baseDir).
                 *
                 * @property {String} leftImage
                 */
                leftImage: {
                    type: &#x27;string&#x27;,
                    description: &#x27;URL of image to show on left&#x27;
                },
                /**
                 * URL of image to show on right, if any. Can be a full URL or a
                 * stub that will be appended to &#x60;baseDir&#x60; + &#x60;img/&#x60; (see
                 * baseDir).
                 *
                 * @property {String} right
                 */
                rightImage: {
                    type: &#x27;string&#x27;,
                    description: &#x27;URL of image to show on left&#x27;
                },
                /**
                 * URL of image to show at center, if any. Can be a full URL or
                 * a stub that will be appended to &#x60;baseDir&#x60; + &#x60;img/&#x60; (see
                 * baseDir).
                 *
                 * @property {String} centerImage
                 */
                centerImage: {
                    type: &#x27;string&#x27;,
                    description: &#x27;URL of image to show on left&#x27;
                },
                /**
                 * minimum amount of time to show attention-getter in seconds.
                 * attention-getter intro video will be shown for at least this
                 * long, and also until any intro audio finishes playing and a
                 * webcam connection is established.
                 *
                 * @property {Number} attnLength
                 * @default 5
                 */
                attnLength: {
                    type: &#x27;number&#x27;,
                    description: &#x27;minimum amount of time to show attention-getter in seconds&#x27;,
                    default: 5
                },
                /**
                 * length of preferential looking trial in seconds. (Only used
                 * if not isCalibrationFrame.)
                 *
                 * @property {Number} trialLength
                 * @default 6
                 */
                trialLength: {
                    type: &#x27;number&#x27;,
                    description: &#x27;length of preferential looking trial in seconds&#x27;,
                    default: 6
                },
                /**
                 * length of single calibration segment in seconds (only used
                 * if isCalibrationFrame)
                 *
                 * @property {Number} calibrationLength
                 * @default 3
                 */
                calibrationLength: {
                    type: &#x27;number&#x27;,
                    description: &#x27;length of single calibration segment in seconds&#x27;,
                    default: 3
                },
                /**
                 * Sources Array of {src: &#x27;url&#x27;, type: &#x27;MIMEtype&#x27;} objects
                 * for audio played during test trial. (Only used if not
                 * isCalibrationFrame.)
                 *
                 * Can also give a single element {stub: &#x27;filename&#x27;}, which will
                 * be expanded out to the appropriate array based on &#x60;baseDir&#x60;
                 * and &#x60;audioTypes&#x60; values; see &#x60;audioTypes&#x60;.
                 *
                 * @property {Object[]} testAudioSources
                 */
                testAudioSources: {
                    type: &#x27;array&#x27;,
                    description: &#x27;List of objects specifying audio src and type for audio played during test trial&#x27;,
                    default: [],
                    items: {
                        type: &#x27;object&#x27;,
                        properties: {
                            &#x27;src&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;type&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;stub&#x27;: {
                                type: &#x27;string&#x27;
                            }
                        }
                    }
                },
                /**
                 * Sources Array of {src: &#x27;url&#x27;, type: &#x27;MIMEtype&#x27;} objects
                 * for instructions or any other audio during attention-getter
                 * video
                 *
                 * Can also give a single element {stub: &#x27;filename&#x27;}, which will
                 * be expanded out to the appropriate array based on &#x60;baseDir&#x60;
                 * and &#x60;audioTypes&#x60; values; see &#x60;audioTypes&#x60;.
                 *
                 * @property {Object[]} introAudioSources
                 */
                introAudioSources: {
                    type: &#x27;array&#x27;,
                    description: &#x27;List of objects specifying audio src and type for instructions during attention-getter video&#x27;,
                    default: [],
                    items: {
                        type: &#x27;object&#x27;,
                        properties: {
                            &#x27;src&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;type&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;stub&#x27;: {
                                type: &#x27;string&#x27;
                            }
                        }
                    }
                },
                /**
                 * Sources Array of {src: &#x27;url&#x27;, type: &#x27;MIMEtype&#x27;} objects
                 * for audio played after trial ends (optional, intended for
                 * use on last trial to let parents know they can open their
                 * eyes)
                 *
                 * Can also give a single element {stub: &#x27;filename&#x27;}, which will
                 * be expanded out to the appropriate array based on &#x60;baseDir&#x60;
                 * and &#x60;audioTypes&#x60; values; see &#x60;audioTypes&#x60;.
                 *
                 * @property {Object[]} endAudioSources
                 */
                endAudioSources: {
                    type: &#x27;array&#x27;,
                    description: &#x27;Supply this to play audio at the end of the trial; list of objects specifying audio src and type&#x27;,
                    default: [],
                    items: {
                        type: &#x27;object&#x27;,
                        properties: {
                            &#x27;src&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;type&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;stub&#x27;: {
                                type: &#x27;string&#x27;
                            }
                        }
                    }
                },
                /**
                 * Sources Array of {src: &#x27;url&#x27;, type: &#x27;MIMEtype&#x27;} objects
                 * for calibration audio, played from start during each
                 * calibration segment (only used if isCalibrationFrame)
                 *
                 * Can also give a single element {stub: &#x27;filename&#x27;}, which will
                 * be expanded out to the appropriate array based on &#x60;baseDir&#x60;
                 * and &#x60;audioTypes&#x60; values; see &#x60;audioTypes&#x60;.
                 *
                 * @property {Object[]} calibrationAudioSources
                 */
                calibrationAudioSources: {
                    type: &#x27;array&#x27;,
                    description: &#x27;list of objects specifying audio src and type for calibration audio&#x27;,
                    default: [],
                    items: {
                        type: &#x27;object&#x27;,
                        properties: {
                            &#x27;src&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;type&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;stub&#x27;: {
                                type: &#x27;string&#x27;
                            }
                        }
                    }
                },
                /**
                 * Sources Array of {src: &#x27;url&#x27;, type: &#x27;MIMEtype&#x27;} objects
                 * for calibration video, played from start during each
                 * calibration segment (only used if isCalibrationFrame)
                 *
                 * Can also give a single element {stub: &#x27;filename&#x27;}, which will
                 * be expanded out to the appropriate array based on &#x60;baseDir&#x60;
                 * and &#x60;videoTypes&#x60; values; see &#x60;videoTypes&#x60;.
                 *
                 * @property {Object[]} calibrationVideoSources
                 */
                calibrationVideoSources: {
                    type: &#x27;array&#x27;,
                    description: &#x27;list of objects specifying video src and type for calibration video&#x27;,
                    default: [],
                    items: {
                        type: &#x27;object&#x27;,
                        properties: {
                            &#x27;src&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;type&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;stub&#x27;: {
                                type: &#x27;string&#x27;
                            }
                        }
                    }
                },
                /**
                 * Sources Array of {src: &#x27;url&#x27;, type: &#x27;MIMEtype&#x27;} objects
                 * for attention-getter video
                 *
                 * Can also give a single element {stub: &#x27;filename&#x27;}, which will
                 * be expanded out to the appropriate array based on &#x60;baseDir&#x60;
                 * and &#x60;videoTypes&#x60; values; see &#x60;videoTypes&#x60;.
                 *
                 * @property {Object[]} videoSources
                 */
                videoSources: {
                    type: &#x27;array&#x27;,
                    description: &#x27;List of objects specifying video src and type for attention-getter video&#x27;,
                    default: [],
                    items: {
                        type: &#x27;object&#x27;,
                        properties: {
                            &#x27;src&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;type&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;stub&#x27;: {
                                type: &#x27;string&#x27;
                            }
                        }
                    }
                },
                /**
                 * Sources Array of {src: &#x27;url&#x27;, type: &#x27;MIMEtype&#x27;} objects for
                 * audio played upon pausing study
                 *
                 * Can also give a single element {stub: &#x27;filename&#x27;}, which will
                 * be expanded out to the appropriate array based on &#x60;baseDir&#x60;
                 * and &#x60;audioTypes&#x60; values; see &#x60;audioTypes&#x60;.
                 *
                 * @property {Object[]} pauseAudio
                 */
                pauseAudio: {
                    type: &#x27;array&#x27;,
                    description: &#x27;List of objects specifying audio src and type for audio played when pausing study&#x27;,
                    default: [],
                    items: {
                        type: &#x27;object&#x27;,
                        properties: {
                            &#x27;src&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;type&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;stub&#x27;: {
                                type: &#x27;string&#x27;
                            }
                        }
                    }
                },
                /**
                 * Sources Array of {src: &#x27;url&#x27;, type: &#x27;MIMEtype&#x27;} objects for
                 * audio played upon resuming study
                 *
                 * Can also give a single element {stub: &#x27;filename&#x27;}, which will
                 * be expanded out to the appropriate array based on &#x60;baseDir&#x60;
                 * and &#x60;audioTypes&#x60; values; see &#x60;audioTypes&#x60;.
                 *
                 * @property {Object[]} unpauseAudio
                 */
                unpauseAudio: {
                    type: &#x27;array&#x27;,
                    description: &#x27;List of objects specifying audio src and type for audio played when pausing study&#x27;,
                    default: [],
                    items: {
                        type: &#x27;object&#x27;,
                        properties: {
                            &#x27;src&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;type&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;stub&#x27;: {
                                type: &#x27;string&#x27;
                            }
                        }
                    }
                },
                /**
                 * Sources Array of {src: &#x27;url&#x27;, type: &#x27;MIMEtype&#x27;} objects for
                 * audio played when study is paused due to not being fullscreen
                 *
                 * Can also give a single element {stub: &#x27;filename&#x27;}, which will
                 * be expanded out to the appropriate array based on &#x60;baseDir&#x60;
                 * and &#x60;audioTypes&#x60; values; see &#x60;audioTypes&#x60;.
                 *
                 * @property {Object[]} fsAudio
                 */
                fsAudio: {
                    type: &#x27;array&#x27;,
                    description: &#x27;List of objects specifying audio src and type for audio played when pausing study if study is not fullscreen&#x27;,
                    default: [],
                    items: {
                        type: &#x27;object&#x27;,
                        properties: {
                            &#x27;src&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;type&#x27;: {
                                type: &#x27;string&#x27;
                            },
                            &#x27;stub&#x27;: {
                                type: &#x27;string&#x27;
                            }
                        }
                    }
                }
            }
        },
        data: {
            /**
             * Parameters captured and sent to the server
             *
             * @method serializeContent
             * @param {String} videoID The ID of any video recorded during this frame
             * @param {Boolean} hasBeenPaused whether this trial was paused
             * @param {Boolean} isCalibrationFrame whether this is a calibration frame (given as a property of the frame)
             * @param {Boolean} allowPausingDuringTest whether the user can return to the test/calibration period after pausing (given as a property of the frame)
             * @param {String} rightImage URL of image shown on right (given as a property of the frame)
             * @param {String} leftImage URL of image shown on left (given as a property of the frame)
             * @param {String} centerImage URL of image shown at center (given as a property of the frame)
             * @param {Number} trialLength seconds to display images if this is a test trial (given as a property of the frame)
             * @param {Number} calibrationLength s to display calibration video in each of four locations if this is a calibration trial (given as a property of the frame)
             * @param {Object[]} testAudioSources Array of {src: &#x27;url&#x27;, type: &#x27;MIMEtype&#x27;} objects for audio played during test trial (given as a property of the frame)
             * @param {Object} eventTimings
             * @return {Object} The payload sent to the server
             */
            type: &#x27;object&#x27;,
            properties: {
                videoId: {
                    type: &#x27;string&#x27;
                },
                hasBeenPaused: {
                    type: &#x27;boolean&#x27;
                },
                isCalibrationFrame: {
                    type: &#x27;boolean&#x27;
                },
                allowPausingDuringTest: {
                    type: &#x27;boolean&#x27;
                },
                rightImage: {
                    type: &#x27;string&#x27;
                },
                leftImage: {
                    type: &#x27;string&#x27;
                },
                centerImage: {
                    type: &#x27;string&#x27;
                },
                trialLength: {
                    type: &#x27;number&#x27;
                },
                testAudioSources: {
                    type: &#x27;object&#x27;
                },
                calibrationLength: {
                    type: &#x27;number&#x27;
                }
            }
        }
    },

    calObserver: Ember.observer(&#x27;readyToStartCalibration&#x27;, function(frame) {
        if (frame.get(&#x27;readyToStartCalibration&#x27;) &amp;&amp; frame.get(&#x27;currentSegment&#x27;) === &#x27;intro&#x27;) {

            if (!this.get(&#x27;skipTest&#x27;)) {
                frame.set(&#x27;currentSegment&#x27;, &#x27;test&#x27;);
                frame.startTrial();
            } else {
                frame.endTrial();
            }
        }
    }),

    actions: {

        // When intro audio is complete
        completedIntroAudio() {
            this.set(&#x27;completedAudio&#x27;, true);
            this.notifyPropertyChange(&#x27;readyToStartCalibration&#x27;);
        },

        next() {
            /**
             * Just before stopping webcam video capture
             *
             * @event stoppingCapture
             */
            this.stopRecorder();
            this._super(...arguments);
        }

    },

    // Utility to expand stubs into either full URLs (for images) or
    // array of {src: &#x27;url&#x27;, type: &#x27;MIMEtype&#x27;} objects (for audio/video).
    // Updates this[&#x27;propertyName&#x27;] based on the appropriate type, which should
    // be &#x27;audio&#x27;, &#x27;video&#x27;, or &#x27;image&#x27;.
    expandAsset(propertyName, type) {

        if (this.hasOwnProperty(propertyName)) {

            var asset = this[propertyName];
            var fullAsset = asset;
            var _this = this;

            if (type === &#x27;image&#x27; &amp;&amp; typeof asset === &#x27;string&#x27; &amp;&amp; !(asset.includes(&#x27;://&#x27;))) {
                // Image: replace stub with full URL if needed
                fullAsset = this.baseDir + &#x27;img/&#x27; + asset;
            } else if (type === &#x27;audio&#x27; || type === &#x27;video&#x27;) {
                // Audio/video: replace any source objects that have a
                // &#x27;stub&#x27; attribute with the appropriate expanded source
                // objects
                fullAsset = [];

                var types = [];
                if (type === &#x27;audio&#x27;) {
                    types = this.audioTypes;
                } else {
                    types = this.videoTypes;
                }

                asset.forEach(function(srcObj) {
                    if (srcObj.hasOwnProperty(&#x27;stub&#x27;)) {
                        for (var iType = 0; iType &lt; types.length; iType++) {
                            fullAsset.push({
                                src: _this.baseDir + types[iType] + &#x27;/&#x27; + srcObj.stub + &#x27;.&#x27; + types[iType],
                                type: type + &#x27;/&#x27; + types[iType]
                            });
                        }
                    } else {
                        fullAsset.push(srcObj);
                    }
                });
            }

            this.set(propertyName + &#x27;_parsed&#x27;, fullAsset);

        }
    },

    startIntro() {

        var _this = this;

        /**
         * Just before starting intro segment
         *
         * @event startIntro
         */
        _this.send(&#x27;setTimeEvent&#x27;, &#x27;startIntro&#x27;);
        $(&#x27;#player-video&#x27;)[0].play();

        // Set a timer for the minimum length for the intro/break
        $(&#x27;#player-audio&#x27;)[0].currentTime = 0;
        $(&#x27;#player-audio&#x27;)[0].play();

        _this.set(&#x27;introTimer&#x27;, window.setTimeout(function() {
            _this.set(&#x27;completedAttn&#x27;, true);
            _this.notifyPropertyChange(&#x27;readyToStartCalibration&#x27;);
        }, _this.get(&#x27;attnLength&#x27;) * 1000));

    },

    startCalibration() {
        var _this = this;

        var calAudio = $(&#x27;#player-calibration-audio&#x27;)[0];
        var calVideo = $(&#x27;#player-calibration-video&#x27;)[0];

        $(&#x27;#player-calibration-video&#x27;).show();

        // Show the calibration segment at center, left, right, center, each
        // time recording an event and playing the calibration audio.
        var doCalibrationSegments = function(calList, lastLoc) {
            if (calList.length === 0) {
                $(&#x27;#player-calibration-video&#x27;).hide();
                _this.endTrial();
            } else {
                var thisLoc = calList.shift();
                /**
                 * Start of EACH calibration segment
                 *
                 * @event startCalibration
                 * @param {String} location location of calibration ball, relative to child: &#x27;left&#x27;, &#x27;right&#x27;, or &#x27;center&#x27;
                 */
                _this.send(&#x27;setTimeEvent&#x27;, &#x27;startCalibration&#x27;,
                    {location: thisLoc});
                calAudio.pause();
                calAudio.currentTime = 0;
                calAudio.play();
                calVideo.pause();
                calVideo.currentTime = 0;
                calVideo.play();
                $(&#x27;#player-calibration-video&#x27;).removeClass(lastLoc);
                $(&#x27;#player-calibration-video&#x27;).addClass(thisLoc);
                _this.set(&#x27;calTimer&#x27;, window.setTimeout(function() {
                    doCalibrationSegments(calList, thisLoc);
                }, 1000 * _this.get(&#x27;calibrationLength&#x27;)));
            }
        };

        $(&#x27;#player-calibration-video&#x27;).removeClass(&#x27;left right&#x27;);
        $(&#x27;#player-calibration-video&#x27;).addClass(&#x27;center&#x27;);
        doCalibrationSegments([&#x27;center&#x27;, &#x27;left&#x27;, &#x27;right&#x27;, &#x27;center&#x27;], &#x27;&#x27;);

    },

    startTrial() {

        var _this = this;

        _this.send(&#x27;setTimeEvent&#x27;, &#x27;startTestTrial&#x27;);

        if (_this.get(&#x27;isCalibrationFrame&#x27;)) { // Calibration frame
            _this.set(&#x27;currentSegment&#x27;, &#x27;calibration&#x27;);
            _this.startCalibration();
        } else { // Regular static image preferential looking frame
            $(&#x27;#allstimuli&#x27;).show();
            _this.set(&#x27;currentSegment&#x27;, &#x27;test&#x27;);

            var $audioPlayer = $(&#x27;#player-test-audio&#x27;);
            $audioPlayer[0].currentTime = 0;
            $audioPlayer[0].play();

            // Now presenting stimuli; stop after trial length.
            _this.set(&#x27;stimTimer&#x27;, window.setTimeout(function() {
                    window.clearTimeout(_this.get(&#x27;stimTimer&#x27;));
                    $audioPlayer[0].pause();
                    $(&#x27;#allstimuli&#x27;).hide();
                    _this.endTrial();
                }, _this.trialLength * 1000));
        }
    },

    // When stimuli have been shown for time indicated: play end-audio if
    // present, or just move on.
    endTrial() {
        // Don&#x27;t allow pausing anymore
        $(document).off(&#x27;keyup.pauser&#x27;);
        this.stopRecorder();
        if (this.get(&#x27;endAudioSources&#x27;).length) {
            this.set(&#x27;currentSegment&#x27;, &#x27;finalaudio&#x27;);
            $(&#x27;#player-endaudio&#x27;)[0].play();
        } else {
            this.send(&#x27;next&#x27;);
        }
    },

    makeTimeEvent(eventName, extra) {
        return this._super(&#x60;exp-lookit-preferential-looking:${eventName}&#x60;, extra);
    },

    // TODO: should the events here be moved to the fullscreen mixin?
    onFullscreen() {
        if (this.get(&#x27;isDestroyed&#x27;)) {
            return;
        }
        this._super(...arguments);
        if (!this.checkFullscreen()) {
            /**
             * Upon detecting change out of fullscreen mode
             *
             * @event leftFullscreen
            */
            this.send(&#x27;setTimeEvent&#x27;, &#x27;leftFullscreen&#x27;);
            if (!(this.get(&#x27;isPaused&#x27;)) &amp;&amp; (this.get(&#x27;currentSegment&#x27;) !== &#x27;finalaudio&#x27;)) {
                this.pauseStudy();
            }
        } else {
            /**
             * Upon detecting change to fullscreen mode
             *
             * @event enteredFullscreen
            */
            this.send(&#x27;setTimeEvent&#x27;, &#x27;enteredFullscreen&#x27;);
        }
    },

    handleSpace(event, frame) {
        // Only pause/unpause on space if study is fullscreen (or not currently paused)
        if (frame.checkFullscreen() || !frame.isPaused) {
            if (event.which === 32) { // space
                frame.pauseStudy();
            }
        }
    },

    // Pause/unpause study.
    pauseStudy() {

        Ember.run.once(this, () =&gt; {
            // Only &quot;count&quot; as pausing if outside of intro segment
            if (!this.get(&#x27;allowPausingDuringTest&#x27;) &amp;&amp; (this.get(&#x27;currentSegment&#x27;) !== &#x27;intro&#x27;)) {
                this.set(&#x27;skipTest&#x27;, true);
            }

            this.set(&#x27;hasBeenPaused&#x27;, true);
            var wasPaused = this.get(&#x27;isPaused&#x27;);

            if (wasPaused) { // Currently paused: RESUME
                $(&#x27;#player-pause-audio, #player-pause-audio-leftfs&#x27;).each(function() {
                    this.pause();
                    this.currentTime = 0;
                });

                /**
                 * When unpausing study, immediately before request to resume webcam recording
                 *
                 * @event unpauseVideo
                 */
                try {
                    this.resumeRecorder();
                } catch (_) {
                    return;
                }
                this.set(&#x27;isPaused&#x27;, false);
                this.startIntro();

            } else { // Not currently paused: PAUSE

                this.set(&#x27;previousSegment&#x27;, this.get(&#x27;currentSegment&#x27;));
                this.set(&#x27;currentSegment&#x27;, &#x27;intro&#x27;);

                $(&#x27;audio, video:not(#player-video)&#x27;).each(function() {
                    this.pause();
                    this.currentTime = 0;
                });

                $(&#x27;#allstimuli&#x27;).hide();
                $(&#x27;#player-calibration-video&#x27;).hide();

                this.set(&#x27;completedAudio&#x27;, false);
                this.set(&#x27;completedAttn&#x27;, false);

                window.clearTimeout(this.get(&#x27;introTimer&#x27;));
                window.clearTimeout(this.get(&#x27;stimTimer&#x27;));
                window.clearTimeout(this.get(&#x27;calTimer&#x27;));

                /**
                 * When pausing study, immediately before request to pause webcam recording
                 *
                 * @event pauseVideo
                 */
                this.pauseRecorder(true);

                if (this.checkFullscreen()) {
                    $(&#x27;#player-pause-audio&#x27;)[0].play();
                } else {
                    $(&#x27;#player-pause-audio-leftfs&#x27;)[0].play();
                }
                this.set(&#x27;isPaused&#x27;, true);
            }
        });

    },

    didInsertElement() {
        this._super(...arguments);

        // Expand any stubs given for image, audio, or video sources, based on
        // baseDir and audioTypes/videoTypes.
        var _this = this;
        [&#x27;rightImage&#x27;, &#x27;leftImage&#x27;, &#x27;centerImage&#x27;].forEach(function(prop) {
            _this.expandAsset(prop, &#x27;image&#x27;);
        });

        [&#x27;testAudioSources&#x27;,
         &#x27;introAudioSources&#x27;,
         &#x27;endAudioSources&#x27;,
         &#x27;calibrationAudioSources&#x27;,
         &#x27;pauseAudio&#x27;,
         &#x27;unpauseAudio&#x27;,
         &#x27;fsAudio&#x27;].forEach(function(prop) {
            _this.expandAsset(prop, &#x27;audio&#x27;);
        });

        [&#x27;calibrationVideoSources&#x27;,
         &#x27;videoSources&#x27;].forEach(function(prop) {
            _this.expandAsset(prop, &#x27;video&#x27;);
        });

        // Begin frame. Actual test trial will start once recording is ready.
        this.send(&#x27;showFullscreen&#x27;);
        $(document).on(&#x27;keyup.pauser&#x27;, function(e) {_this.handleSpace(e, _this);});
        this.startIntro();

        // TODO: move handlers that just record events to the VideoRecord mixin?
        if (this.get(&#x27;experiment&#x27;) &amp;&amp; this.get(&#x27;id&#x27;) &amp;&amp; this.get(&#x27;session&#x27;)) {
            const installPromise = this.setupRecorder(this.$(&#x27;#videoRecorder&#x27;), true, {
                hidden: true
            });
            installPromise.then(() =&gt; {
                this.send(&#x27;setTimeEvent&#x27;, &#x27;recorderReady&#x27;);
                this.set(&#x27;recordingIsReady&#x27;, true);
            });
        }
    },

    willDestroyElement() {
        this.send(&#x27;setTimeEvent&#x27;, &#x27;destroyingElement&#x27;);

        // Whenever the component is destroyed, make sure that event handlers are removed and video recorder is stopped
        const recorder = this.get(&#x27;recorder&#x27;);
        if (recorder) {
            recorder.hide(); // Hide the webcam config screen
            this.stopRecorder();
        }
        // Remove pause handler
        $(document).off(&#x27;keyup.pauser&#x27;);

        this._super(...arguments);
    }

});

    </pre>
</div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
<script src="../assets/vendor/prettify/prettify-min.js"></script>
<script>prettyPrint();</script>
<script src="../assets/js/yui-prettify.js"></script>
<script src="../assets/../api.js"></script>
<script src="../assets/js/api-filter.js"></script>
<script src="../assets/js/api-list.js"></script>
<script src="../assets/js/api-search.js"></script>
<script src="../assets/js/apidocs.js"></script>
</body>
</html>
